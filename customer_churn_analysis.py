# -*- coding: utf-8 -*-
"""Customer churn analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fh79tzNmL6fw1_B12NqwJDczI22OcKC4
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.preprocessing
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import OneHotEncoder

data = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')

data

data.isnull().sum()

data.dtypes

data.replace({False: 0, True: 1}, inplace=True)

data

data.replace({'No': 0, 'Yes': 1}, inplace=True)

data.replace({'Male': 0, 'Female': 1}, inplace = True)

new_data = data.select_dtypes(include=['int64', 'float64'])

new_data

sns.heatmap(new_data.corr(), annot=True)

def tenure_group (tenure):
  if tenure <= 24 :
    return ('0-1 year')
  elif tenure <= 48 :
    return ('1-2 year')
  elif tenure <= 60 :
    return ('2-3 year')
  elif tenure <= 72 :
    return ('3-4 year')
  else:
    return ('5 year+')

data['tenure_group'] =  data['tenure'].apply(tenure_group)

data

data['tenure_group'].value_counts()
data

data['InternetService'].value_counts()

data['tenure_group'].value_counts()

columns_to_encode =  ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
       'StreamingTV', 'StreamingMovies']
data[columns_to_encode] = data[columns_to_encode].astype(str)

encoder = OneHotEncoder(sparse_output=False)

# Step 2: Fit and transform the selected columns
encoded = encoder.fit_transform(data[ ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
       'StreamingTV', 'StreamingMovies']])

encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(columns_to_encode))
encoded_df.index = data.index

# Drop original columns and join encoded ones
data.drop(columns=columns_to_encode, inplace=True)
data = pd.concat([data, encoded_df], axis=1)

data

data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

data['TotalCharges'].fillna(data['TotalCharges'].median(), inplace=True)

from sklearn.preprocessing import StandardScaler

Columns_to_scale = ['MonthlyCharges', 'TotalCharges', 'tenure']
scaler = StandardScaler()
data[Columns_to_scale] = scaler.fit_transform(data[Columns_to_scale])

data

data['TotalCharges']

final_data = data.drop(['customerID', 'tenure_group'], axis=1)

final_data.columns

print(final_data.select_dtypes(include='object').columns)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

X = final_data.drop('Churn', axis=1)
y = final_data['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X, y)

coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Importance': model.coef_[0]
}).sort_values(by='Importance', ascending=False)

print(coefficients.head(10))  # Top churn drivers

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

y_probs = model.predict_proba(X_test)[:, 1]  # probability of churn = 1

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--', label='No Skill')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Customer Churn')
plt.legend()
plt.show()



"""Xgboost

"""

import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

X = final_data.drop('Churn', axis=1)
y = final_data['Churn']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # Suppress warning
model.fit(X_train, y_train)

# Predict classes and probabilities
y_pred_XGBoost = model.predict(X_test)
y_probs_XGBoost = model.predict_proba(X_test)[:, 1]

# Evaluation
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_probs))

import matplotlib.pyplot as plt

xgb.plot_importance(model, max_num_features=10)
plt.title("Top 10 Feature Importances")
plt.tight_layout()
plt.show()

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_probs_XGBoost)
roc_auc = auc(fpr, tpr)
# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--', label='No Skill')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Customer Churn')
plt.legend()
plt.show()

